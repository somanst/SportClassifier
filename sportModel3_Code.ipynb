{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch_directml\n",
    "from torchvision import transforms, datasets\n",
    "from torch.utils.data import DataLoader\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import torchvision\n",
    "import torch.optim as optim\n",
    "from sklearn.metrics import confusion_matrix, accuracy_score, precision_score, recall_score, f1_score\n",
    "from IPython.display import Markdown, display\n",
    "import pandas as pd\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "dml = torch_directml.device(torch_directml.default_device())\n",
    "\n",
    "transformer = transforms.Compose([\n",
    "    transforms.ToTensor(),  \n",
    "    transforms.Normalize(mean=[0.5, 0.5, 0.5], std=[0.5, 0.5, 0.5])         # Convert PIL images to PyTorch tensors\n",
    "])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_metrics(y_pred, y_true):\n",
    "    # Confusion Matrix\n",
    "    cm = confusion_matrix(y_true, y_pred)\n",
    "    print(\"Confusion Matrix:\")\n",
    "    print(cm)\n",
    "\n",
    "    # Accuracy\n",
    "    acc = accuracy_score(y_true, y_pred)\n",
    "    print(f\"Accuracy: {acc:.2f}\")\n",
    "\n",
    "    # Precision\n",
    "    precision = precision_score(y_true, y_pred, average='weighted', zero_division=0)\n",
    "    print(f\"Precision: {precision:.2f}\")\n",
    "\n",
    "    # Recall\n",
    "    recall = recall_score(y_true, y_pred, average='weighted', zero_division=0)\n",
    "    print(f\"Recall: {recall:.2f}\")\n",
    "\n",
    "    # F1\n",
    "    f1 = f1_score(y_true, y_pred, average='weighted', zero_division=0)\n",
    "    print(f\"F1 Score: {f1:.2f}\\n\")\n",
    "\n",
    "    return [round(acc, 3) ,round(float(precision), 3), round(float(recall), 3), round(float(f1), 3)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "class EarlyStopping:\n",
    "    def __init__(self, patience=5, delta=0.0, path='models/best_model.pth'):\n",
    "        self.patience = patience\n",
    "        self.delta = delta\n",
    "        self.path = path\n",
    "        self.counter = 0\n",
    "        self.best_loss = float('inf')\n",
    "        self.early_stop = False\n",
    "\n",
    "    def __call__(self, val_loss, model):\n",
    "        if val_loss < self.best_loss - self.delta:\n",
    "            self.best_loss = val_loss\n",
    "            self.counter = 0\n",
    "            self.save_checkpoint(model)\n",
    "        else:\n",
    "            self.counter += 1\n",
    "            if self.counter >= self.patience:\n",
    "                self.early_stop = True\n",
    "\n",
    "    def save_checkpoint(self, model):\n",
    "        torch.save(model.state_dict(), self.path)\n",
    "\n",
    "class MLP(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.fc1 = nn.Linear(224 * 224 * 3, 1024) #wX + b\n",
    "        self.fc2 = nn.Linear(1024, 256)\n",
    "        self.fc3 = nn.Linear(256, 100)\n",
    "        \n",
    "        self.activation = F.relu # max(0, x)\n",
    "            \n",
    "\n",
    "    def forward(self, x):\n",
    "        x = torch.flatten(x, 1) #flatten image 2d vector into 1d\n",
    "        x = self.activation(self.fc1(x))\n",
    "        x = self.activation(self.fc2(x))\n",
    "        x = F.sigmoid(self.fc3(x))\n",
    "\n",
    "        return x\n",
    "\n",
    "class noBNCNN(nn.Module):\n",
    "    def __init__(self, n):\n",
    "        super().__init__()\n",
    "        self.conv1 = nn.Conv2d(3, 8  * n, 11, 3)\n",
    "  \n",
    "        self.conv2 = nn.Conv2d(8  * n, 12 * n, 5, 1, 2)\n",
    "    \n",
    "        self.conv3 = nn.Conv2d(12 * n, 20*n, 3, 1, 1)\n",
    "   \n",
    "        self.conv4 = nn.Conv2d(20*n, 20*n, 3, 1, 1)\n",
    "        \n",
    "        self.conv5 = nn.Conv2d(20*n, 4 * n, 3, 1, 1)\n",
    "        \n",
    "        self.fc1 = nn.Linear(9 * 9 * 4*n, 256)\n",
    "        self.fc2 = nn.Linear(256, 100)\n",
    "        #self.fc3 = nn.Linear(256, 100)\n",
    "        self.pool1 = nn.MaxPool2d(2, 2)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.pool1(F.relu(self.conv1(x)))\n",
    "        x = self.pool1(F.relu(self.conv2(x)))\n",
    "        x = F.relu(self.conv3(x))\n",
    "        x = F.relu(self.conv4(x))\n",
    "        x = self.pool1(F.relu(self.conv5(x)))\n",
    "        x = torch.flatten(x, 1)\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = self.fc2(x)\n",
    "        #x = self.fc3(x)\n",
    "\n",
    "        return x\n",
    "\n",
    "\n",
    "class CNN(nn.Module):\n",
    "    def __init__(self, n):\n",
    "        super().__init__()\n",
    "        self.conv1 = nn.Conv2d(3, 8  * n, 11, 3)\n",
    "        self.bn1 = nn.BatchNorm2d(8  * n)\n",
    "        self.conv2 = nn.Conv2d(8  * n, 12 * n, 5, 1, 2)\n",
    "        self.bn2 = nn.BatchNorm2d(12 * n)\n",
    "        self.conv3 = nn.Conv2d(12 * n, 20*n, 3, 1, 1)\n",
    "        self.bn3 = nn.BatchNorm2d(20*n)\n",
    "        self.conv4 = nn.Conv2d(20*n, 20*n, 3, 1, 1)\n",
    "        self.bn4 = nn.BatchNorm2d(20*n)\n",
    "        self.conv5 = nn.Conv2d(20*n, 4 * n, 3, 1, 1)\n",
    "        self.bn5 = nn.BatchNorm2d(4*n)\n",
    "        self.fc1 = nn.Linear(9 * 9 * 4*n, 256)\n",
    "        self.fc2 = nn.Linear(256, 100)\n",
    "        #self.fc3 = nn.Linear(256, 100)\n",
    "        self.pool1 = nn.MaxPool2d(2, 2)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.pool1(F.relu(self.bn1(self.conv1(x))))\n",
    "        x = self.pool1(F.relu(self.bn2(self.conv2(x))))\n",
    "        x = F.relu(self.bn3(self.conv3(x)))\n",
    "        x = F.relu(self.bn4(self.conv4(x)))\n",
    "        x = self.pool1(F.relu(self.bn5(self.conv5(x))))\n",
    "        x = torch.flatten(x, 1)\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = self.fc2(x)\n",
    "        #x = self.fc3(x)\n",
    "\n",
    "        return x\n",
    "    \n",
    "class CNNLES(nn.Module):\n",
    "    def __init__(self, n):\n",
    "        super().__init__()\n",
    "        self.conv1 = nn.Conv2d(3, 8*n, 11, 3)\n",
    "        self.bn1 = nn.BatchNorm2d(8*n)\n",
    "        self.pool1 = nn.MaxPool2d(2, 2)\n",
    "        self.conv2 = nn.Conv2d(8*n, 4*n, 3)\n",
    "        self.bn2 = nn.BatchNorm2d(4*n)\n",
    "        self.fc1 = nn.Linear(17 * 17 * 4*n, 17 * 17)\n",
    "        self.fc2 = nn.Linear(17 * 17, 100) #20\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.pool1(F.relu(self.bn1(self.conv1(x))))\n",
    "        x = self.pool1(F.relu(self.bn2(self.conv2(x))))\n",
    "        x = torch.flatten(x, 1)\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = self.fc2(x)\n",
    "\n",
    "        return x\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def testModel(model, error, transform, path):\n",
    "    model.eval()\n",
    "\n",
    "    preds = []\n",
    "    processedLabels = []\n",
    "\n",
    "    test = datasets.ImageFolder(root= path + 'valid', transform=transform)\n",
    "    testLoader = DataLoader(test, batch_size=1)\n",
    "\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "    torch.cuda.empty_cache()\n",
    "\n",
    "    testError = 0.0\n",
    "\n",
    "    for i, data in enumerate(testLoader, 0):\n",
    "        # get the inputs; data is a list of [inputs, labels]\n",
    "        inputs, labels = data\n",
    "\n",
    "        # forward + backward + optimize\n",
    "        with torch.no_grad():\n",
    "            outputs = model(inputs.to(dml))\n",
    "        outputs = outputs.squeeze(dim=-1) \n",
    "        loss = criterion(outputs, labels.to(dml))\n",
    "        testError += loss.item()\n",
    "        \n",
    "        preds.append(outputs.argmax().item())\n",
    "\n",
    "        del outputs\n",
    "\n",
    "        processedLabels.append(labels.item())\n",
    "\n",
    "\n",
    "    if error:\n",
    "        return testError/len(testLoader)\n",
    "    \n",
    "    threshold = 0.5\n",
    "    # binary_list = threshold_to_binary(preds, threshold)\n",
    "    return print_metrics(preds, processedLabels)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model, lr, batch_size, transformer, num_epochs, path):\n",
    "    print(\"Training..\")\n",
    "\n",
    "    dataset = datasets.ImageFolder(root= path + 'train', transform=transformer)\n",
    "    dataloader = DataLoader(dataset, batch_size=batch_size, shuffle=True)\n",
    "    \n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    optimizer = optim.SGD(model.parameters(), lr=lr, momentum=0.9)\n",
    "\n",
    "    early_stopping = EarlyStopping(patience=2, delta=0.01)\n",
    "\n",
    "    trainLossi = []\n",
    "    testLossi = []\n",
    "    lossi = []\n",
    "    indexi = []\n",
    "\n",
    "    step = 0\n",
    "    ranEpochs = 0\n",
    "\n",
    "    for epoch in range(num_epochs):  # loop over the dataset multiple times\n",
    "        model.train()\n",
    "        running_loss = 0.0\n",
    "        cycleLoss = 0.0\n",
    "        for i, data in enumerate(dataloader, 0):\n",
    "            # get the inputs; data is a list of [inputs, labels]\n",
    "            inputs, labels = data\n",
    "\n",
    "            # zero the parameter gradients\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            # forward + backward + optimize\n",
    "            outputs = model(inputs.to(dml))\n",
    "            outputs = outputs.squeeze()\n",
    "            loss = criterion(outputs, labels.to(dml))\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            del inputs\n",
    "            del labels\n",
    "\n",
    "            running_loss += loss.item()\n",
    "            cycleLoss += loss.item()\n",
    "\n",
    "            step += 1\n",
    "            if i % 5 == 4:\n",
    "                lossi.append(cycleLoss / 5)\n",
    "                indexi.append(step)\n",
    "                cycleLoss = 0.0\n",
    "        trainLossi.append(running_loss/len(dataloader))\n",
    "        valLoss = testModel(model, True, transformer, path)\n",
    "        testLossi.append(valLoss)\n",
    "        print(\"█▄\", end = \"\")\n",
    "        ranEpochs += 1\n",
    "\n",
    "        early_stopping(valLoss, model)\n",
    "        if early_stopping.early_stop:\n",
    "            print(\"Early stopping triggered\")\n",
    "            break\n",
    "\n",
    "    print('\\nFinished Training')\n",
    "    return [indexi, lossi, trainLossi, testLossi, ranEpochs]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plotTrainTestError(num_epochs, trainLoss, testLoss):\n",
    "    plt.figure(figsize=(12, 8))  # Width: 10 inches, Height: 6 inches\n",
    "\n",
    "\n",
    "    plt.plot(range(num_epochs), trainLoss, label='Train Error', color='blue', linestyle='--')\n",
    "    plt.plot(range(num_epochs), testLoss, label='Test Error', color='red', linestyle='-')\n",
    "\n",
    "    # Add labels and legend\n",
    "    plt.xlabel('Epochs')\n",
    "    plt.ylabel('Error')\n",
    "    plt.title('Train vs Test Error')\n",
    "    plt.legend()  # Display the legend\n",
    "\n",
    "    # Show the plot\n",
    "    plt.show()\n",
    "\n",
    "def plotTrainError(index, loss):\n",
    "    plt.figure(figsize=(12, 8))\n",
    "\n",
    "    plt.plot(index, loss)\n",
    "    plt.title(\"Loss VS Time Through All Epochs\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "text = \"\"\"\n",
    "## Modeling\n",
    "\"\"\"\n",
    "display(Markdown(text))\n",
    "\n",
    "inputSize = 224\n",
    "epoch_num = 10\n",
    "i = -1\n",
    "batch_size = 32\n",
    "lr = 0.005\n",
    "activation = \"Relu\"\n",
    "path = \"smallDataset/\"\n",
    "\n",
    "\n",
    "CNNModels = []\n",
    "\n",
    "for batch_size in [16, 32]:\n",
    "    for n in [2, 6, 10]:\n",
    "        for typee in [CNN, CNNLES, noBNCNN]:\n",
    "            text = f\"\"\"\n",
    "### Model Attributes:\n",
    "- Type: {typee.__name__}\n",
    "- Learning Rate: {lr}\n",
    "- Input Size: {inputSize}\n",
    "- Activation Function: {activation}\n",
    "- Batch Size: {batch_size}\n",
    "- Epoch Count: {epoch_num}\n",
    "    \"\"\"\n",
    "            display(Markdown(text))\n",
    "\n",
    "            model = typee(n).to(dml)\n",
    "\n",
    "            transform = transformer\n",
    "\n",
    "            metrics = train(model, lr, batch_size, transform, epoch_num, path)\n",
    "\n",
    "            text = \"\"\"### Results: \"\"\"\n",
    "            display(Markdown(text))\n",
    "\n",
    "            finalMetrics = testModel(model, False, transform, path)\n",
    "            plotTrainError(metrics[0], metrics[1])\n",
    "            print()\n",
    "            plotTrainTestError(metrics[4], metrics[2], metrics[3])\n",
    "\n",
    "            i += 1\n",
    "\n",
    "            modelDetails = [typee.__name__, batch_size, n, lr, activation]\n",
    "            modelDetails.extend(finalMetrics)\n",
    "            CNNModels.append(modelDetails)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame(CNNModels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "typee = MLP\n",
    "\n",
    "\n",
    "text = f\"\"\"\n",
    "### Model Attributes:\n",
    "- Type: {typee.__name__}\n",
    "- Learning Rate: {lr}\n",
    "- Input Size: {inputSize}\n",
    "- Activation Function: {activation}\n",
    "- Batch Size: {batch_size}\n",
    "- Epoch Count: {epoch_num}\n",
    "    \"\"\"\n",
    "display(Markdown(text))\n",
    "\n",
    "model = typee().to(dml)\n",
    "\n",
    "transform = transformer\n",
    "\n",
    "metrics = train(model, lr, batch_size, transform, epoch_num, path)\n",
    "\n",
    "text = \"\"\"### Results: \"\"\"\n",
    "display(Markdown(text))\n",
    "\n",
    "finalMetrics = testModel(model, False, transform, path)\n",
    "plotTrainError(metrics[0], metrics[1])\n",
    "print()\n",
    "plotTrainTestError(epoch_num, metrics[2], metrics[3])\n",
    "\n",
    "i += 1\n",
    "\n",
    "modelDetails = [typee.__name__, batch_size, n, lr, activation]\n",
    "modelDetails.extend(finalMetrics)\n",
    "CNNModels.append(modelDetails)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "text = \"\"\"\n",
    "## Modeling\n",
    "\"\"\"\n",
    "display(Markdown(text))\n",
    "\n",
    "inputSize = 224\n",
    "epoch_num = 10\n",
    "i = -1\n",
    "batch_size = 64\n",
    "lr = 0.005\n",
    "activation = \"Relu\"\n",
    "path = \"dataset/\"\n",
    "\n",
    "\n",
    "CNNModels = []\n",
    "\n",
    "text = f\"\"\"\n",
    "### Model Attributes:\n",
    "- Learning Rate: {lr}\n",
    "- Input Size: {inputSize}\n",
    "- Activation Function: {activation}\n",
    "- Batch Size: {batch_size}\n",
    "- Epoch Count: {epoch_num}\n",
    "    \"\"\"\n",
    "display(Markdown(text))\n",
    "\n",
    "#model = CNN().to(dml)\n",
    "\n",
    "transform = transformer\n",
    "\n",
    "metrics = train(model, lr, batch_size, transform, epoch_num, path)\n",
    "\n",
    "text = \"\"\"### Results: \"\"\"\n",
    "display(Markdown(text))\n",
    "\n",
    "finalMetrics = testModel(model, False, transform, path)\n",
    "plotTrainError(metrics[0], metrics[1])\n",
    "print()\n",
    "plotTrainTestError(epoch_num, metrics[2], metrics[3])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
